import jax
import jax.random as random

import torch
from sdot import SdotPlanSampler
from sdot import rebalance
from tqdm import tqdm


def generate_tensor_from_seed(key, shape):
    return random.normal(key, shape)


def generate_tensor_from_seeds_vmap(keys, shape, device=jax.devices("cpu")):
    return jax.vmap(lambda key: generate_tensor_from_seed(key, shape))(keys)


def get_keys(num_keys, seed=0):
    master_key = jax.random.PRNGKey(seed)
    keys = jax.random.split(master_key, num=num_keys + 1)
    master_key = keys[0]
    sub_keys = keys[1:]
    return master_key, sub_keys


def generate_sdot_dataset(data_tensor, dual_weight, num_epoch, batch_size=256):
    """
    This function generate a set of keys and target index, s.t. the noise generate from the key should be matched to target index by SDOT map.
    Parameters:
        data_tensor: the dataset. Shape: [num_targets, dim].
        dual_weight: generated by sdot_solve. Shape: [num_targets, dim].
        eps_entropic: when non-zero, target index will be sampled from the softmax distribution.
    Return:
        keys, target_idx: 2 lists where (keys[i], target_idx[i]) will be feed to the model for flow matching training.
    Note:
        Setting non-zero eps_entropic will lead to randomness in the matching between noise and targets.
    """
    gpu_id = data_tensor.get_device()
    device = f"cuda:{gpu_id}"
    device = torch.device(device)

    jax_gpu = jax.devices("gpu")[gpu_id]
    dual_weight = dual_weight.to(device)

    seed = torch.randint(0, 2**32 - 1, (1,)).item()
    master_key, keys = get_keys(len(data_tensor) * num_epoch, seed=seed)

    keys = jax.device_put(keys, jax_gpu)
    data_tensor_shape = list(data_tensor.shape)
    image_shape = data_tensor_shape[1:]

    target_idx = torch.zeros(len(keys), dtype=torch.int64)
    ot_sampler = SdotPlanSampler(data_tensor)
    ot_sampler.set_dual_weight(dual_weight)
    for i in tqdm(range(0, len(keys), batch_size), position=gpu_id):
        current_keys = keys[i : min(i + batch_size, len(keys))]
        noise = generate_tensor_from_seeds_vmap(current_keys, image_shape)

        _, _, target_idx_minibatch = ot_sampler.sample_plan(
            torch.from_dlpack(jax.dlpack.to_dlpack(noise)), None
        )
        target_idx[i : min(i + batch_size, len(keys))] = (
            target_idx_minibatch.squeeze().cpu()
        )

    target_idx = rebalance(target_idx, num_targets=len(ot_sampler.data_tensor))[0]

    target_idx = target_idx.to(dtype=torch.int64)

    return keys, target_idx
